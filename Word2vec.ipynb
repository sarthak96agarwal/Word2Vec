{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_json('reddit_jokes.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Now I have to say \"Leroy can you please paint ...</td>\n",
       "      <td>5tz52q</td>\n",
       "      <td>1</td>\n",
       "      <td>I hate how you cant even say black paint anymore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pizza doesn't scream when you put it in the ov...</td>\n",
       "      <td>5tz4dd</td>\n",
       "      <td>0</td>\n",
       "      <td>What's the difference between a Jew in Nazi Ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>...and being there really helped me learn abou...</td>\n",
       "      <td>5tz319</td>\n",
       "      <td>0</td>\n",
       "      <td>I recently went to America....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Sunday school teacher is concerned that his ...</td>\n",
       "      <td>5tz2wj</td>\n",
       "      <td>1</td>\n",
       "      <td>Brian raises his hand and says, “He’s in Heaven.”</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>He got caught trying to sell the two books to ...</td>\n",
       "      <td>5tz1pc</td>\n",
       "      <td>0</td>\n",
       "      <td>You hear about the University book store worke...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body      id  score  \\\n",
       "0  Now I have to say \"Leroy can you please paint ...  5tz52q      1   \n",
       "1  Pizza doesn't scream when you put it in the ov...  5tz4dd      0   \n",
       "2  ...and being there really helped me learn abou...  5tz319      0   \n",
       "3  A Sunday school teacher is concerned that his ...  5tz2wj      1   \n",
       "4  He got caught trying to sell the two books to ...  5tz1pc      0   \n",
       "\n",
       "                                               title  \n",
       "0   I hate how you cant even say black paint anymore  \n",
       "1  What's the difference between a Jew in Nazi Ge...  \n",
       "2                     I recently went to America....  \n",
       "3  Brian raises his hand and says, “He’s in Heaven.”  \n",
       "4  You hear about the University book store worke...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=df['body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def normalize_text(text):\n",
    "\n",
    "    text=text.lower()\n",
    "    text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+)|(pic\\.twitter\\.com/[^\\s]+))','', text)\n",
    "    text = re.sub('@[^\\s]+','', text)\n",
    "    text = re.sub('#([^\\s]+)', '', text)\n",
    "    text = re.sub('[:;>?<=*+()&,\\-#!$%\\{˜|\\}\\[^_\\\\@\\]1234567890’‘]',' ', text)\n",
    "    text = re.sub('[\\d]','', text)\n",
    "    text = text.replace(\".\", '')\n",
    "    text = text.replace(\"'\", '')\n",
    "    text = text.replace(\"`\", '')\n",
    "    text = text.replace(\"'s\", '')\n",
    "    text = text.replace(\"/\", ' ')\n",
    "    text = text.replace(\"\\\"\", ' ')\n",
    "    text = text.replace(\"\\\\\", '')\n",
    "    re.sub(' +', ' ', text)\n",
    "    text=text.replace('\\n', ' ').replace('\\r', ' ').replace('\\t', ' ')\n",
    "    #normalize some utf8 encoding\n",
    "    text = text.replace(\"\\x9d\",'').replace(\"\\x8c\",'')\n",
    "    text = text.replace(\"\\xa0\",'')\n",
    "    text = text.replace(\"\\x9d\\x92\", '').replace(\"\\x9a\\xaa\\xf0\\x9f\\x94\\xb5\", '').replace(\"\\xf0\\x9f\\x91\\x8d\\x87\\xba\\xf0\\x9f\\x87\\xb8\", '').replace(\"\\x9f\",'').replace(\"\\x91\\x8d\",'')\n",
    "    text = text.replace(\"\\xf0\\x9f\\x87\\xba\\xf0\\x9f\\x87\\xb8\",'').replace(\"\\xf0\",'').replace('\\xf0x9f','').replace(\"\\x9f\\x91\\x8d\",'').replace(\"\\x87\\xba\\x87\\xb8\",'')\n",
    "    text = text.replace(\"\\xe2\\x80\\x94\",'').replace(\"\\x9d\\xa4\",'').replace(\"\\x96\\x91\",'').replace(\"\\xe1\\x91\\xac\\xc9\\x8c\\xce\\x90\\xc8\\xbb\\xef\\xbb\\x89\\xd4\\xbc\\xef\\xbb\\x89\\xc5\\xa0\\xc5\\xa0\\xc2\\xb8\",'')\n",
    "    text = text.replace(\"\\xe2\\x80\\x99s\", \"\").replace(\"\\xe2\\x80\\x98\", '').replace(\"\\xe2\\x80\\x99\", '').replace(\"\\xe2\\x80\\x9c\", \"\").replace(\"\\xe2\\x80\\x9d\", \"\")\n",
    "    text = text.replace(\"\\xe2\\x82\\xac\", \"\").replace(\"\\xc2\\xa3\", \"\").replace(\"\\xc2\\xa0\", \"\").replace(\"\\xc2\\xab\", \"\").replace(\"\\xf0\\x9f\\x94\\xb4\", \"\").replace(\"\\xf0\\x9f\\x87\\xba\\xf0\\x9f\\x87\\xb8\\xf0\\x9f\", \"\")\n",
    "    text =  re.sub(r\"\\b[a-z]\\b\", \"\", text)\n",
    "    text=re.sub( '\\s+', ' ', text).strip()\n",
    "    \n",
    "    text=re.sub(r'\\.+', \".\", text)\n",
    "    text=re.sub(r'\\.\\.+', ' ', text).replace('.', '')\n",
    "    # Replace multiple dots with space\n",
    "    text = re.sub('\\.\\.+', ' ', text) \n",
    "    # Remove single dots\n",
    "    text = re.sub('\\.', '', text)\n",
    "    text = re.sub(r'\\.{2,}', ' ', text)\n",
    "    text = re.sub(r'\\.{1}', '', text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "normed_text=[]\n",
    "for sentence in df['body']:\n",
    "    normed_text.append(normalize_text(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word count 81101\n"
     ]
    }
   ],
   "source": [
    "#Number of unique words\n",
    "import collections\n",
    "words=\" \".join(normed_text).split() \n",
    "count= collections.Counter(words).most_common()\n",
    "print (\"Word count\", len(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a vocabulary\n",
    "unique_words = [i[0] for i in count]\n",
    "vocabulary={}\n",
    "for i, word in enumerate(unique_words):\n",
    "    vocabulary[word]=i\n",
    "vocab_size=len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make word indexes\n",
    "word_index=[]\n",
    "for word in words:\n",
    "    word_index.append(vocabulary[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make skimgram pairs\n",
    "window = 1\n",
    "skipgram_words=[]\n",
    "for i in range(1, len(words)-1):\n",
    "    skipgram_words.append([words[i], words[i-1]])\n",
    "    skipgram_words.append([words[i], words[i+1]])\n",
    "    \n",
    "skipgram_indexes=[]\n",
    "for i in range(1, len(word_index)-1):\n",
    "    skipgram_indexes.append([word_index[i], word_index[i-1]])\n",
    "    skipgram_indexes.append([word_index[i], word_index[i+1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(size):\n",
    "    assert size<len(skipgram_indexes)\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    rdm = np.random.choice(range(len(skipgram_indexes)),size,replace=False)\n",
    "    \n",
    "    for r in rdm:\n",
    "        X.append(skipgram_indexes[r][0])\n",
    "        Y.append(skipgram_indexes[r][1])\n",
    "    return X , Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size=2\n",
    "x=tf.placeholder(shape=[vocab_size, 1], dtype=tf.float32, name=\"x\")\n",
    "y=tf.placeholder(shape=[vocab_size, 1], dtype=tf.float32, name=\"y\")\n",
    "W1 = tf.Variable(tf.random_uniform([vocab_size,embed_size],-1.0,1.0))\n",
    "W2= tf.Variable(tf.random_uniform([embed_size,vocab_size],-1.0,1.0))\n",
    "h1=tf.matmul(tf.transpose(W1), x)\n",
    "h2=tf.matmul(tf.transpose(W2), h1)\n",
    "Loss = -tf.matmul(tf.transpose(h2), y)+tf.log(tf.reduce_sum(tf.exp(h2), axis=1))\n",
    "optimizer = tf.train.AdamOptimizer(1e-1).minimize(Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10000\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        batch_inputs, batch_labels = get_batch(batch_size)\n",
    "        _,loss_val=sess.run([optimizer,loss],feed_dict = {X : batch_inputs, Y : batch_labels })\n",
    "        \n",
    "        if epoch % 1000 == 0:\n",
    "            print(\"Loss at \", epoch, loss_val) # Report the loss\n",
    "    \n",
    "    # Final embeddings are ready for you to use. Need to normalize for practical use\n",
    "    trained_embeddings = embeddings.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
